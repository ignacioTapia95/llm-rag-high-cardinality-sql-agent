{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177a940d",
   "metadata": {},
   "source": [
    "# Manejo de Categorías de Alta Cardinalidad en Bases de Conocimiento SQL para Agentes LLM tipo RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1aac6",
   "metadata": {},
   "source": [
    "Este proyecto utiliza un sistema de embeddings basado en TF-IDF para identificar similitudes de escritura entre variables categóricas de alta cardinalidad en tablas SQL. A continuación, se describe cada paso del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "from langchain_google_firestore import FirestoreVectorStore\n",
    "\n",
    "from WordMatchSim.tfidf import SimpleTfidfVectorizer\n",
    "from WordMatchSim.distance_metrics import cosine_similarity\n",
    "from WordMatchSim.embeddings import CustomTfidfEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_PROJECT = os.getenv(\"GCP_PROJECT\")\n",
    "GCP_FIRESTORE_DATABASE = os.getenv(\"GCP_FIRESTORE_DATABASE\")\n",
    "GCP_FIRESTORE_COLLECTION = os.getenv(\"GCP_FIRESTORE_COLLECTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dec75",
   "metadata": {},
   "source": [
    "### Definición de las variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a03e1",
   "metadata": {},
   "source": [
    "En esta sección, se define una lista de marcas (variable categórica) que servirán como ejemplo para generar los vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_words = [\n",
    "    \"Nike\", \"Adidas\", \"Puma\", \"Under Armour\", \"Reebok\", \"Asics\", \"New Balance\", \"Converse\", \"Vans\", \"Fila\",\n",
    "    \"Columbia Sportswear\", \"Patagonia\", \"The North Face\", \"Mizuno\", \"Salomon\", \"Saucony\", \"Brooks\", \"Lululemon\",\n",
    "    \"Quiksilver\", \"Roxy\", \"Billabong\", \"O'Neill\", \"Rip Curl\", \"DC Shoes\", \"Oakley\", \"Helly Hansen\", \"La Sportiva\",\n",
    "    \"Hoka One One\", \"Merrell\", \"K-Swiss\", \"Skechers\", \"Kappa\", \"Ellesse\", \"Diadora\", \"Umbro\", \"Speedo\",\n",
    "    \"Arena\", \"Castore\", \"Dunlop\", \"Prince\", \"Wilson\", \"Head\", \"Babolat\", \"Yonex\", \"Spalding\", \"Slazenger\",\n",
    "    \"Callaway\", \"Titleist\", \"Ping\", \"TaylorMade\", \"Cobra Golf\", \"FootJoy\", \"Ecco\", \"Garmin\", \"Polar\", \"Suunto\",\n",
    "    \"Timberland\", \"Mountain Hardwear\", \"Arc'teryx\", \"Gore-Tex\", \"Hummel\", \"Joma\", \"Lotto\", \"Macron\",\n",
    "    \"Mammut\", \"Odlo\", \"Ortovox\", \"Peak Performance\", \"Rab\", \"Dynafit\", \"Icebreaker\", \"Black Diamond\",\n",
    "    \"Carhartt\", \"Champion\", \"Everlast\", \"Le Coq Sportif\", \"Lonsdale\", \"Mitre\", \"Penfield\", \"Protest\",\n",
    "    \"Reef\", \"RVCA\", \"Volcom\", \"Altra\", \"Bogner\", \"Descente\", \"Eleven by Venus\", \"Errea\", \"Fila\",\n",
    "    \"Gregory\", \"Huf\", \"Iffley Road\", \"Karhu\", \"Karbon\", \"Karrimor\", \"Kjus\", \"Montbell\", \"Napapijri\",\n",
    "    \"Norrona\", \"Ortlieb\", \"Rains\", \"Samsonite\", \"Schöffel\", \"Sea to Summit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1a42c",
   "metadata": {},
   "source": [
    "### Creación del vectorizador TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf93ca",
   "metadata": {},
   "source": [
    "Se utiliza `SimpleTfidfVectorizer` para crear un vectorizador basado en TF-IDF que genera n-gramas de caracteres. Este enfoque permite capturar similitudes en la escritura de las marcas al descomponer las palabras en secuencias de caracteres. En este caso, se utilizan bigramas (`ngram_range=(1, 2)`) para tokenizar cada palabra, lo cual es adecuado dado la corta longitud de los documentos (nombres de marcas) en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = SimpleTfidfVectorizer(analyzer='char', ngram_range=(1, 2))\n",
    "vectorizer.fit(categorical_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c8ed21",
   "metadata": {},
   "source": [
    "### Generación de vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddf999",
   "metadata": {},
   "source": [
    "El vectorizador TF-IDF previamente creado es encapsulado dentro de una clase Embeddings de LangChain. Este paso permite que el vectorizador sea interpretado como un servicio de embeddings dentro del ecosistema de LangChain, facilitando su integración en flujos de trabajo RAG con LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CustomTfidfEmbeddings(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176618dd",
   "metadata": {},
   "source": [
    "### Cálculo de vectores de las categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfbc73",
   "metadata": {},
   "source": [
    "Se calculan los vectores correspondientes a las categorías (en este caso marcas) utilizando el método de embeddings y se almacenan para futuras comparaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vectors = embeddings.embed_documents(categorical_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f85e1",
   "metadata": {},
   "source": [
    "### Generación de un vector de consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b47c0",
   "metadata": {},
   "source": [
    "Aquí se toma una palabra de consulta (por ejemplo, 'esquetchers') y se genera su embedding. Este embedding será comparado con los vectores de las categorias (marcas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_word = \"esquetchers\"\n",
    "query_vector = embeddings.embed_query(query_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f07b55",
   "metadata": {},
   "source": [
    "### Cálculo de la similitud coseno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c9cee",
   "metadata": {},
   "source": [
    "Se utiliza la similitud coseno para comparar el vector de consulta con los vectores de las palabras categóricas y se identifica la categoría más similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La palabra más similar a 'esquetchers' es 'Skechers'\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_vector, categorical_vectors)\n",
    "most_similar_index = np.argmax(similarities)\n",
    "most_similar_word = categorical_words[most_similar_index]\n",
    "print(f\"La palabra más similar a '{query_word}' es '{most_similar_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f38a3",
   "metadata": {},
   "source": [
    "### Conexión y carga a Firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349ffec",
   "metadata": {},
   "source": [
    "A continuación, se conecta a la base de datos Firestore de Google Cloud y se almacenan los vectores junto con las palabras categóricas en una colección llamada `brands`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = firestore.Client(\n",
    "    project=GCP_PROJECT,\n",
    "    database=GCP_FIRESTORE_DATABASE\n",
    ")\n",
    "\n",
    "for word, vector in tqdm(zip(categorical_words, categorical_vectors)):\n",
    "    document = {\n",
    "        \"content\": word,\n",
    "        \"embedding\": Vector(vector)\n",
    "    }\n",
    "\n",
    "    db.collection(GCP_FIRESTORE_COLLECTION).document(\n",
    "        str(uuid.uuid4())).set(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec269a",
   "metadata": {},
   "source": [
    "### Verificación de las dimensiones de los vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fe52d",
   "metadata": {},
   "source": [
    "Se imprimen las dimensiones de los vectores generados para asegurar que coinciden con lo esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emdedding dimension: 380\n"
     ]
    }
   ],
   "source": [
    "n_documents, vector_dim = np.array(categorical_vectors).shape\n",
    "print(f'Emdedding dimension: {vector_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75545d8",
   "metadata": {},
   "source": [
    "### Creación de índices en Firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ab6e0",
   "metadata": {},
   "source": [
    "Se ejecuta un comando para crear índices en Firestore, lo que optimiza las búsquedas vectoriales sobre los vectores almacenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "!gcloud firestore indexes composite create --project=GCP_PROJECT --collection-group=GCP_FIRESTORE_COLLECTION --query-scope=COLLECTION --field-config=vector-config='{\"dimension\":\"380\",\"flat\": \"{}\"}',field-path=embedding\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d334a3dd",
   "metadata": {},
   "source": [
    "### Búsqueda por similitud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f70760",
   "metadata": {},
   "source": [
    "Finalmente, se utiliza el `FirestoreVectorStore` para realizar una búsqueda por similitud, recuperando los documentos más cercanos en función de los vectores generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FirestoreVectorStore(\n",
    "    client=db,\n",
    "    collection=GCP_FIRESTORE_COLLECTION,\n",
    "    embedding_service=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skechers\n",
      "Descente\n",
      "Converse\n",
      "Ellesse\n",
      "Protest\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = vector_store.similarity_search('esquetchers', 5)\n",
    "\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "categorical-word-similarity-FzesgKEX-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
